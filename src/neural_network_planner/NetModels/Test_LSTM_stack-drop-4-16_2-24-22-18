TEST: LSTM_stack-drop-4-16 DATE: 2 24 22:18 
 PARAMETERS: 
 TRAIN_SIZE = 7656 
 VALID_SIZE = 6261 
 train_batch_size = 16 
 iter_size = 1 
 batch_updates = 1 
  base_learning_rate = 0.01000 
 weight_decay = 0.000100 
 loss_data = [ 
    0.1677       0.0000  ; 
    0.1430       0.0684  ; 
    0.1390       0.0684  ; 
    0.1381       0.0684  ; 
    0.1357       0.0680  ; 
    0.1362       0.0680  ; 
    0.1360       0.0680  ; 
    0.1351       0.0696  ; 
    0.1347       0.0696  ; 
    0.1341       0.0696  ; 
    0.1328       0.0672  ; 
    0.1329       0.0672  ; 
    0.1328       0.0672  ; 
    0.1311       0.0689  ; 
    0.1324       0.0689  ; 
    0.1316       0.0689  ; 
    0.1315       0.0688  ; 
    0.1317       0.0688  ; 
    0.1314       0.0688  ; 
    0.1308       0.0690  ; 
    0.1310       0.0690  ; 
    0.1309       0.0690  ; 
    0.1307       0.0711  ; 
    0.1307       0.0711  ; 
    0.1303       0.0711  ; 
    0.1305       0.0790  ; 
    0.1307       0.0790  ; 
    0.1294       0.0790  ; 
    0.1307       0.0936  ; 
    0.1299       0.0936  ; 
    0.1293       0.0936  ; 
    0.1293       0.1171  ; 
    0.1299       0.1171  ; 
    0.1300       0.1171  ; 
    0.1297       0.1174  ; 
    0.1297       0.1174  ; 
    0.1282       0.1174  ; 
    0.1293       0.1171  ; 
    0.1291       0.1171  ; 
    0.1291       0.1171  ; 
    0.1293       0.1142  ; 
    0.1295       0.1142  ; 
    0.1295       0.1142  ; 
    0.1297       0.0967  ; 
    0.1295       0.0967  ; 
    0.1291       0.0967  ; 
    0.1288       0.0765  ; 
    0.1290       0.0765  ; 
    0.1285       0.0765  ; 
    0.1289       0.0673  ; 
    0.1298       0.0673  ; 
    0.1293       0.0673  ; 
    0.1290       0.0685  ; 
    0.1292       0.0685  ; 
    0.1294       0.0685  ; 
    0.1283       0.0696  ; 
    0.1289       0.0696  ; 
    0.1288       0.0696  ; 
    0.1298       0.0697  ; 
    0.1296       0.0697  ; 
    0.1289       0.0697  ; 
    0.1286       0.0688  ; 
    0.1282       0.0688  ; 
    0.1269       0.0688  ; 
    0.1286       0.0762  ; 
    0.1290       0.0762  ; 
    0.1290       0.0762  ; 
    0.1284       0.0755  ; 
    0.1287       0.0755  ; 
    0.1298       0.0755  ; 
    0.1282       0.0709  ; 
    0.1278       0.0709  ; 
    0.1298       0.0709  ; 
    0.1284       0.0762  ; 
    0.1283       0.0762  ; 
    0.1267       0.0762  ; 
    0.1281       0.1078  ; 
    0.1290       0.1078  ; 
    0.1290       0.1078  ; 
    0.1278       0.1171  ; 
    0.1288       0.1171  ; 
    0.1288       0.1171  ; 
    0.1298       0.1271  ; 
    0.1291       0.1271  ; 
    0.1284       0.1271  ; 
    0.1268       0.1350  ; 
    0.1268       0.1350  ; 
    0.1292       0.1350  ; 
    0.1291       0.1059  ; 
    0.1286       0.1059  ; 
    0.1285       0.1059  ; 
    0.1290       0.0750  ; 
    0.1287       0.0750  ; 
    0.1284       0.0750  ; 
    0.1276       0.0721  ; 
    0.1292       0.0721  ; 
    0.1287       0.0721  ; 
    0.1277       0.0799  ; 
    0.1292       0.0799  ; 
    0.1285       0.0799  ; 
    0.1287       0.0802  ; 
    0.1289       0.0802  ; 
    0.1288       0.0802  ; 
    0.1280       0.0782  ; 
    0.1290       0.0782  ; 
    0.1282       0.0782  ; 
    0.1283       0.0775  ; 
    0.1292       0.0775  ; 
    0.1290       0.0775  ; 
    0.1279       0.0723  ; 
    0.1272       0.0723  ; 
    0.1286       0.0723  ; 
    0.1281       0.0766  ; 
    0.1282       0.0766  ; 
    0.1287       0.0766  ; 
    0.1281       0.0889  ; 
    0.1271       0.0889  ; 
    0.1285       0.0889  ; 
    0.1288       0.1039  ; 
    0.1293       0.1039  ; 
    0.1285       0.1039  ; 
    0.1277       0.1089  ; 
    0.1281       0.1089  ; 
    0.1290       0.1089  ; 
    0.1291       0.1157  ; 
