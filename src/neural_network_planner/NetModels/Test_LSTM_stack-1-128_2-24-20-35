TEST: LSTM_stack-1-128 DATE: 2 24 20:35 
 PARAMETERS: 
 TRAIN_SIZE = 7656 
 VALID_SIZE = 6261 
 train_batch_size = 16 
 iter_size = 1 
 batch_updates = 1 
  base_learning_rate = 0.01000 
 weight_decay = 0.000100 
 loss_data = [ 
    0.2497       0.0000  ; 
    0.1684       0.0825  ; 
    0.1682       0.0825  ; 
    0.1681       0.0825  ; 
    0.1672       0.0814  ; 
    0.1682       0.0814  ; 
    0.1682       0.0814  ; 
    0.1680       0.0849  ; 
    0.1681       0.0849  ; 
    0.1681       0.0849  ; 
    0.1678       0.0862  ; 
    0.1679       0.0862  ; 
    0.1681       0.0862  ; 
    0.1668       0.0895  ; 
    0.1689       0.0895  ; 
    0.1681       0.0895  ; 
    0.1684       0.0854  ; 
    0.1681       0.0854  ; 
    0.1681       0.0854  ; 
    0.1680       0.0851  ; 
    0.1678       0.0851  ; 
    0.1673       0.0851  ; 
    0.1667       0.0938  ; 
    0.1673       0.0938  ; 
    0.1665       0.0938  ; 
    0.1664       0.1110  ; 
    0.1667       0.1110  ; 
    0.1696       0.1110  ; 
    0.1678       0.1334  ; 
    0.1665       0.1334  ; 
    0.1667       0.1334  ; 
    0.1660       0.1503  ; 
    0.1645       0.1503  ; 
    0.1659       0.1503  ; 
    0.1654       0.1599  ; 
    0.1655       0.1599  ; 
    0.1666       0.1599  ; 
    0.1652       0.1544  ; 
    0.1657       0.1544  ; 
    0.1663       0.1544  ; 
    0.1665       0.1447  ; 
    0.1662       0.1447  ; 
    0.1664       0.1447  ; 
    0.1662       0.1188  ; 
    0.1658       0.1188  ; 
    0.1658       0.1188  ; 
    0.1652       0.0900  ; 
    0.1651       0.0900  ; 
    0.1642       0.0900  ; 
    0.1639       0.0789  ; 
    0.1643       0.0789  ; 
    0.1633       0.0789  ; 
    0.1637       0.0797  ; 
    0.1643       0.0797  ; 
    0.1629       0.0797  ; 
    0.1642       0.0808  ; 
    0.1630       0.0808  ; 
    0.1633       0.0808  ; 
    0.1628       0.0816  ; 
    0.1634       0.0816  ; 
    0.1620       0.0816  ; 
    0.1625       0.0803  ; 
    0.1612       0.0803  ; 
    0.1609       0.0803  ; 
    0.1618       0.0847  ; 
    0.1616       0.0847  ; 
    0.1612       0.0847  ; 
    0.1621       0.0868  ; 
    0.1612       0.0868  ; 
    0.1618       0.0868  ; 
    0.1609       0.0827  ; 
    0.1602       0.0827  ; 
    0.1598       0.0827  ; 
    0.1611       0.0922  ; 
    0.1601       0.0922  ; 
    0.1586       0.0922  ; 
    0.1615       0.1173  ; 
    0.1602       0.1173  ; 
    0.1608       0.1173  ; 
    0.1603       0.1641  ; 
    0.1585       0.1641  ; 
    0.1613       0.1641  ; 
    0.1589       0.1759  ; 
    0.1604       0.1759  ; 
    0.1594       0.1759  ; 
    0.1580       0.2012  ; 
    0.1561       0.2012  ; 
    0.1694       0.2012  ; 
    0.1554       0.1526  ; 
    0.1554       0.1526  ; 
    0.1619       0.1526  ; 
    0.1567       0.1591  ; 
    0.1643       0.1591  ; 
    0.1563       0.1591  ; 
    0.1602       0.1078  ; 
    0.1545       0.1078  ; 
    0.1637       0.1078  ; 
    0.1533       0.1619  ; 
    0.1653       0.1619  ; 
    0.1581       0.1619  ; 
    0.1582       0.1332  ; 
    0.1543       0.1332  ; 
    0.1666       0.1332  ; 
    0.1527       0.1652  ; 
    0.1629       0.1652  ; 
    0.1576       0.1652  ; 
    0.1572       0.1196  ; 
    0.1551       0.1196  ; 
    0.1605       0.1196  ; 
    0.1620       0.0907  ; 
    0.1545       0.0907  ; 
    0.1572       0.0907  ; 
    0.1624       0.1023  ; 
    0.1573       0.1023  ; 
    0.1557       0.1023  ; 
    0.1597       0.1182  ; 
    0.1543       0.1182  ; 
    0.1609       0.1182  ; 
    0.1585       0.1442  ; 
    0.1561       0.1442  ; 
    0.1524       0.1442  ; 
    0.1630       0.1497  ; 
    0.1531       0.1497  ; 
    0.1616       0.1497  ; 
    0.1516       0.1764  ; 
    0.1581       0.1764  ; 
    0.1562       0.1764  ; 
    0.1589       0.1484  ; 
    0.1550       0.1484  ; 
    0.1534       0.1484  ; 
    0.1544       0.1183  ; 
    0.1541       0.1183  ; 
    0.1666       0.1183  ; 
    0.1466       0.0899  ; 
    0.1546       0.0899  ; 
    0.1507       0.0899  ; 
